{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "noble-hepatitis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random \n",
    "SPARK_HOME = \"/usr/hdp/current/spark2-client\"\n",
    "PYSPARK_PYTHON = \"/opt/conda/envs/dsenv/bin/python\"\n",
    "os.environ[\"PYSPARK_PYTHON\"]= PYSPARK_PYTHON\n",
    "os.environ[\"SPARK_HOME\"] = SPARK_HOME\n",
    "\n",
    "PYSPARK_HOME = os.path.join(SPARK_HOME, \"python/lib\")\n",
    "sys.path.insert(0, os.path.join(PYSPARK_HOME, \"py4j-0.10.7-src.zip\"))\n",
    "sys.path.insert(0, os.path.join(PYSPARK_HOME, \"pyspark.zip\"))\n",
    "SPARK_UI_PORT = random.choice(range(10000, 10200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-fraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "    #\n",
    "    # Relabel\n",
    "    #\n",
    "    \n",
    "    #\n",
    "    # Нечто странное\n",
    "    #\n",
    "    train_flag = (data.where(F.col(\"label\").isNull()).count() == 0)\n",
    "    if not train_flag: df2 = df2.drop('label')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "distant-mother",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml import Estimator, Transformer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "covered-source",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf()\n",
    "conf.set(\"spark.ui.port\", SPARK_UI_PORT)\n",
    "spark = SparkSession.builder.config(conf=conf).appName(\"HW5b\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel('WARN')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "narrative-track",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = '/datasets/amazon/all_reviews_5_core_train_extra_small_sentiment.json'\n",
    "processed_data_path = 'HW5/processed.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "continuing-fight",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "        StructField(\"asin\", StringType()),\n",
    "        StructField(\"id\", LongType()),\n",
    "        StructField(\"label\", IntegerType()),\n",
    "        StructField(\"reviewText\", StringType()),\n",
    "        StructField(\"reviewTime\", DateType()),\n",
    "        StructField(\"reviewerID\", StringType()),\n",
    "        StructField(\"reviewerName\", StringType()),\n",
    "        StructField(\"vote\", IntegerType()),\n",
    "        StructField(\"summary\", StringType()),\n",
    "        StructField(\"unixReviewTime\", TimestampType()),\n",
    "        StructField(\"verified\", BooleanType())\n",
    "    ])\n",
    "\n",
    "dataset = spark.read.json(raw_data_path, schema=schema,dateFormat='MM dd, yyyy').cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "figured-alarm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------\n",
      " asin           | B000VX4W78           \n",
      " id             | 72900                \n",
      " label          | 1                    \n",
      " reviewText     | Purchased these f... \n",
      " reviewTime     | 2009-11-30           \n",
      " reviewerID     | A3BH3XJBBU7FF2       \n",
      " reviewerName   | The Dragon           \n",
      " vote           | null                 \n",
      " summary        | Works great, nice... \n",
      " unixReviewTime | 2009-11-30 00:00:00  \n",
      " verified       | true                 \n",
      "-RECORD 1------------------------------\n",
      " asin           | B0017U1KBK           \n",
      " id             | 104280               \n",
      " label          | 1                    \n",
      " reviewText     | This thing is too... \n",
      " reviewTime     | 2017-01-04           \n",
      " reviewerID     | A408FUV9TO4EA        \n",
      " reviewerName   | Amber                \n",
      " vote           | null                 \n",
      " summary        | Five Stars           \n",
      " unixReviewTime | 2017-01-04 00:00:00  \n",
      " verified       | true                 \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.show(2, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "demonstrated-beijing",
   "metadata": {},
   "outputs": [],
   "source": [
    "droper = SQLTransformer(statement=\"SELECT * FROM __THIS__ WHERE reviewText is not null\")\n",
    "tokenizer = Tokenizer(inputCol=\"reviewText\", outputCol=\"words\")\n",
    "hasher = HashingTF(numFeatures=100, binary=True, inputCol=tokenizer.getOutputCol(), outputCol=\"word_vector\")\n",
    "pipeline = Pipeline(stages=[\n",
    "        droper,\n",
    "        tokenizer,\n",
    "        hasher        \n",
    "    ])\n",
    "processed_dataset = pipeline.fit(dataset).transform(dataset).select(\"id\", \"label\", \"word_vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "curious-monitor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------\n",
      " id          | 72900                \n",
      " label       | 1                    \n",
      " word_vector | (100,[2,3,4,10,11... \n",
      "-RECORD 1---------------------------\n",
      " id          | 104280               \n",
      " label       | 1                    \n",
      " word_vector | (100,[16,34,44,46... \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processed_dataset.show(2, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "choice-rhythm",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_array_to_list(col):\n",
    "    def to_list(v):\n",
    "        return v.toArray().tolist()\n",
    "    return F.udf(to_list, ArrayType(DoubleType()))(col)\n",
    "\n",
    "processed_dataset = processed_dataset.select([\"id\", \"label\", split_array_to_list(F.col(\"word_vector\")).alias(\"val\")])\\\n",
    "        .select([\"id\", \"label\"] + [F.col(\"val\")[i] for i in range(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bigger-picture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------\n",
      " id      | 72900  \n",
      " label   | 1      \n",
      " val[0]  | 0.0    \n",
      " val[1]  | 0.0    \n",
      " val[2]  | 1.0    \n",
      " val[3]  | 1.0    \n",
      " val[4]  | 1.0    \n",
      " val[5]  | 0.0    \n",
      " val[6]  | 0.0    \n",
      " val[7]  | 0.0    \n",
      " val[8]  | 0.0    \n",
      " val[9]  | 0.0    \n",
      " val[10] | 1.0    \n",
      " val[11] | 1.0    \n",
      " val[12] | 0.0    \n",
      " val[13] | 0.0    \n",
      " val[14] | 0.0    \n",
      " val[15] | 0.0    \n",
      " val[16] | 0.0    \n",
      " val[17] | 0.0    \n",
      " val[18] | 0.0    \n",
      " val[19] | 0.0    \n",
      " val[20] | 1.0    \n",
      " val[21] | 0.0    \n",
      " val[22] | 0.0    \n",
      " val[23] | 0.0    \n",
      " val[24] | 1.0    \n",
      " val[25] | 1.0    \n",
      " val[26] | 1.0    \n",
      " val[27] | 1.0    \n",
      " val[28] | 1.0    \n",
      " val[29] | 0.0    \n",
      " val[30] | 1.0    \n",
      " val[31] | 1.0    \n",
      " val[32] | 0.0    \n",
      " val[33] | 0.0    \n",
      " val[34] | 0.0    \n",
      " val[35] | 1.0    \n",
      " val[36] | 1.0    \n",
      " val[37] | 1.0    \n",
      " val[38] | 0.0    \n",
      " val[39] | 0.0    \n",
      " val[40] | 1.0    \n",
      " val[41] | 0.0    \n",
      " val[42] | 0.0    \n",
      " val[43] | 0.0    \n",
      " val[44] | 0.0    \n",
      " val[45] | 1.0    \n",
      " val[46] | 1.0    \n",
      " val[47] | 0.0    \n",
      " val[48] | 0.0    \n",
      " val[49] | 0.0    \n",
      " val[50] | 0.0    \n",
      " val[51] | 0.0    \n",
      " val[52] | 0.0    \n",
      " val[53] | 0.0    \n",
      " val[54] | 0.0    \n",
      " val[55] | 0.0    \n",
      " val[56] | 0.0    \n",
      " val[57] | 1.0    \n",
      " val[58] | 0.0    \n",
      " val[59] | 0.0    \n",
      " val[60] | 0.0    \n",
      " val[61] | 1.0    \n",
      " val[62] | 0.0    \n",
      " val[63] | 0.0    \n",
      " val[64] | 0.0    \n",
      " val[65] | 1.0    \n",
      " val[66] | 1.0    \n",
      " val[67] | 0.0    \n",
      " val[68] | 1.0    \n",
      " val[69] | 1.0    \n",
      " val[70] | 1.0    \n",
      " val[71] | 0.0    \n",
      " val[72] | 1.0    \n",
      " val[73] | 0.0    \n",
      " val[74] | 0.0    \n",
      " val[75] | 0.0    \n",
      " val[76] | 1.0    \n",
      " val[77] | 0.0    \n",
      " val[78] | 1.0    \n",
      " val[79] | 1.0    \n",
      " val[80] | 1.0    \n",
      " val[81] | 0.0    \n",
      " val[82] | 1.0    \n",
      " val[83] | 0.0    \n",
      " val[84] | 1.0    \n",
      " val[85] | 1.0    \n",
      " val[86] | 0.0    \n",
      " val[87] | 0.0    \n",
      " val[88] | 1.0    \n",
      " val[89] | 1.0    \n",
      " val[90] | 0.0    \n",
      " val[91] | 1.0    \n",
      " val[92] | 1.0    \n",
      " val[93] | 1.0    \n",
      " val[94] | 0.0    \n",
      " val[95] | 0.0    \n",
      " val[96] | 0.0    \n",
      " val[97] | 0.0    \n",
      " val[98] | 1.0    \n",
      " val[99] | 1.0    \n",
      "-RECORD 1---------\n",
      " id      | 104280 \n",
      " label   | 1      \n",
      " val[0]  | 0.0    \n",
      " val[1]  | 0.0    \n",
      " val[2]  | 0.0    \n",
      " val[3]  | 0.0    \n",
      " val[4]  | 0.0    \n",
      " val[5]  | 0.0    \n",
      " val[6]  | 0.0    \n",
      " val[7]  | 0.0    \n",
      " val[8]  | 0.0    \n",
      " val[9]  | 0.0    \n",
      " val[10] | 0.0    \n",
      " val[11] | 0.0    \n",
      " val[12] | 0.0    \n",
      " val[13] | 0.0    \n",
      " val[14] | 0.0    \n",
      " val[15] | 0.0    \n",
      " val[16] | 1.0    \n",
      " val[17] | 0.0    \n",
      " val[18] | 0.0    \n",
      " val[19] | 0.0    \n",
      " val[20] | 0.0    \n",
      " val[21] | 0.0    \n",
      " val[22] | 0.0    \n",
      " val[23] | 0.0    \n",
      " val[24] | 0.0    \n",
      " val[25] | 0.0    \n",
      " val[26] | 0.0    \n",
      " val[27] | 0.0    \n",
      " val[28] | 0.0    \n",
      " val[29] | 0.0    \n",
      " val[30] | 0.0    \n",
      " val[31] | 0.0    \n",
      " val[32] | 0.0    \n",
      " val[33] | 0.0    \n",
      " val[34] | 1.0    \n",
      " val[35] | 0.0    \n",
      " val[36] | 0.0    \n",
      " val[37] | 0.0    \n",
      " val[38] | 0.0    \n",
      " val[39] | 0.0    \n",
      " val[40] | 0.0    \n",
      " val[41] | 0.0    \n",
      " val[42] | 0.0    \n",
      " val[43] | 0.0    \n",
      " val[44] | 1.0    \n",
      " val[45] | 0.0    \n",
      " val[46] | 1.0    \n",
      " val[47] | 0.0    \n",
      " val[48] | 0.0    \n",
      " val[49] | 0.0    \n",
      " val[50] | 0.0    \n",
      " val[51] | 0.0    \n",
      " val[52] | 0.0    \n",
      " val[53] | 0.0    \n",
      " val[54] | 0.0    \n",
      " val[55] | 0.0    \n",
      " val[56] | 0.0    \n",
      " val[57] | 0.0    \n",
      " val[58] | 0.0    \n",
      " val[59] | 0.0    \n",
      " val[60] | 0.0    \n",
      " val[61] | 0.0    \n",
      " val[62] | 0.0    \n",
      " val[63] | 0.0    \n",
      " val[64] | 0.0    \n",
      " val[65] | 0.0    \n",
      " val[66] | 0.0    \n",
      " val[67] | 0.0    \n",
      " val[68] | 0.0    \n",
      " val[69] | 0.0    \n",
      " val[70] | 0.0    \n",
      " val[71] | 0.0    \n",
      " val[72] | 0.0    \n",
      " val[73] | 1.0    \n",
      " val[74] | 0.0    \n",
      " val[75] | 1.0    \n",
      " val[76] | 0.0    \n",
      " val[77] | 0.0    \n",
      " val[78] | 0.0    \n",
      " val[79] | 0.0    \n",
      " val[80] | 0.0    \n",
      " val[81] | 1.0    \n",
      " val[82] | 0.0    \n",
      " val[83] | 0.0    \n",
      " val[84] | 0.0    \n",
      " val[85] | 0.0    \n",
      " val[86] | 1.0    \n",
      " val[87] | 0.0    \n",
      " val[88] | 0.0    \n",
      " val[89] | 0.0    \n",
      " val[90] | 0.0    \n",
      " val[91] | 0.0    \n",
      " val[92] | 0.0    \n",
      " val[93] | 1.0    \n",
      " val[94] | 0.0    \n",
      " val[95] | 0.0    \n",
      " val[96] | 0.0    \n",
      " val[97] | 0.0    \n",
      " val[98] | 0.0    \n",
      " val[99] | 0.0    \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processed_dataset.show(2, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "based-chase",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_path = 'HW5/processed_test.parquet'\n",
    "processed_dataset.coalesce(1).write.parquet(processed_data_path,mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-fleet",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsenv",
   "language": "python",
   "name": "dsenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
