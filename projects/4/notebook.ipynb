{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "muslim-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "SPARK_HOME = \"/usr/hdp/current/spark2-client\"\n",
    "PYSPARK_PYTHON = \"/opt/conda/envs/dsenv/bin/python\"\n",
    "os.environ[\"PYSPARK_PYTHON\"]= PYSPARK_PYTHON\n",
    "os.environ[\"SPARK_HOME\"] = SPARK_HOME\n",
    "\n",
    "PYSPARK_HOME = os.path.join(SPARK_HOME, \"python/lib\")\n",
    "sys.path.insert(0, os.path.join(PYSPARK_HOME, \"py4j-0.10.7-src.zip\"))\n",
    "sys.path.insert(0, os.path.join(PYSPARK_HOME, \"pyspark.zip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "educational-singer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark UI port is: 10190\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "SPARK_UI_PORT = random.choice(range(10000, 10200))\n",
    "print(f\"Spark UI port is: {SPARK_UI_PORT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "spectacular-tours",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.ui.port\", SPARK_UI_PORT)\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).appName(\"Spark ML Intro\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "regulation-vienna",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml import Estimator, Transformer\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "rough-desert",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_path = '/datasets/amazon/all_reviews_5_core_train_small.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "thousand-forth",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"asin\", StringType()),\n",
    "    StructField(\"id\", LongType()),\n",
    "    StructField(\"overall\", DoubleType()),\n",
    "    StructField(\"reviewText\", StringType()),\n",
    "    StructField(\"reviewTime\", DateType()),\n",
    "    StructField(\"reviewerID\", StringType()),\n",
    "    StructField(\"reviewerName\", StringType()),\n",
    "    StructField(\"vote\", IntegerType()),\n",
    "    StructField(\"summary\", StringType()),\n",
    "    StructField(\"unixReviewTime\", TimestampType()),\n",
    "    StructField(\"verified\", BooleanType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "colonial-translator",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = spark.read.json(small_train_path, schema=schema,dateFormat='MM dd, yyyy').cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "lonely-female",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "comic-actress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------\n",
      " asin           | B00005MDZ8           \n",
      " id             | 6500                 \n",
      " overall        | 5.0                  \n",
      " reviewText     | quick shipping, g... \n",
      " reviewTime     | 2014-10-23           \n",
      " reviewerID     | AEZ4DZCUL021H        \n",
      " reviewerName   | Stephen              \n",
      " vote           | null                 \n",
      " summary        | great product        \n",
      " unixReviewTime | 2014-10-23 00:00:00  \n",
      " verified       | true                 \n",
      "-RECORD 1------------------------------\n",
      " asin           | B000DZE0XK           \n",
      " id             | 42580                \n",
      " overall        | 5.0                  \n",
      " reviewText     | Most delicious Ever! \n",
      " reviewTime     | 2016-02-13           \n",
      " reviewerID     | A3UPMJ5WQFHGLN       \n",
      " reviewerName   | Pelipen              \n",
      " vote           | null                 \n",
      " summary        | Five Stars           \n",
      " unixReviewTime | 2016-02-13 00:00:00  \n",
      " verified       | true                 \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.show(2, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "boxed-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna(subset='reviewText')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "confirmed-mixer",
   "metadata": {},
   "outputs": [],
   "source": [
    "droper = SQLTransformer(statement=\"SELECT * FROM __THIS__ WHERE reviewText is not null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "persistent-private",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = sqlTrans.transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "parliamentary-civilian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|reviewText|\n",
      "+----------+\n",
      "|         0|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset2.select([count(when(isnan(c), c)).alias(c) for c in ['reviewText']]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "significant-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"reviewText\", outputCol=\"words\")\n",
    "#dataset2 = tokenizer.transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ahead-throw",
   "metadata": {},
   "outputs": [],
   "source": [
    "hasher = HashingTF(numFeatures=100, binary=True, inputCol=tokenizer.getOutputCol(), outputCol=\"word_vector\")\n",
    "#dataset2 = hasher.transform(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "paperback-relevance",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol=hasher.getOutputCol(), labelCol=\"overall\", maxIter=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "answering-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[\n",
    "    droper,\n",
    "    tokenizer,\n",
    "    hasher,\n",
    "    lr\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "neutral-nation",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = dataset.randomSplit([0.7, 0.3],42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "distinct-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "conservative-fault",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "popular-romania",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"overall\",metricName=\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "separated-heather",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 1.13703\n"
     ]
    }
   ],
   "source": [
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % lr_evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "automatic-combat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[asin: string, id: bigint, overall: double, reviewText: string, reviewTime: date, reviewerID: string, reviewerName: string, vote: int, summary: string, unixReviewTime: timestamp, verified: boolean, words: array<string>, word_vector: vector, prediction: double]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "proprietary-adapter",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "explainParams() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-848cc592d01e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplainParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: explainParams() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "Tokenizer.explainParams() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-thumb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsenv",
   "language": "python",
   "name": "dsenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
